## 0.3.0

- support for dartantic_ai
- make use of `LlmFailureException`
- added example projects for the other providers

## 0.2.0

- Added support for access to local models via llama.cpp
- Added an example

## 0.1.0

- Initial release with support for:
  * OpenAI (GPT-4, o1, etc.)
  * Anthropic (Claude)
  * Ollama (Local Models)
  * OpenAI-compatible APIs (OpenRouter, xAI, Groq, etc.)
